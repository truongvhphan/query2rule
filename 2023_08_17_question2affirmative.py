# -*- coding: utf-8 -*-
"""2023_08_17_Question2affirmative.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OZmAE4XXceLo-m05Zf4YiE_OoV5RChTL
"""
import stanza
def question_to_affirmative(question):
    if question.endswith('?'):
        question = question[:-1]  # Remove the question mark

    words = question.split()  # Split the question into words

    if words[0].lower() in ['is', 'am', 'are', 'was', 'were', 'do', 'does', 'did', 'has', 'have', 'had', 'will', 'can', 'could', 'shall', 'should', 'may', 'might', 'would']:
        affirmative = ' '.join(words[1:])  # Remove the auxiliary verb
    else:
        affirmative = ' '.join(words)

    return affirmative.capitalize() + '.'  # Capitalize the first letter and add a period

# # Example usage
# question = "Are you going to the party?"
# affirmative_sentence = question_to_affirmative(question)
# print(affirmative_sentence)

# ChatGPT: Write a Python Code to change a Who Question to affirmative sentence
def who_question_to_affirmative(question):
    # question=question.lower()
    if question.find("Who") > -1 or question.find("who") > -1:
        question = question[:-1]  # Remove the question mark

        words = question.split()  # Split the question into words
        # print(words)
        if question.find("Who") > -1:
            action_index = words.index("Who") + 1  # Find the index of the action verb
        elif question.find("who") > -1:
            action_index = words.index("who") + 1  # Find the index of the action verb

        if action_index >= len(words):
            return "Invalid 'Who' question."

        subject = "X"
        action = words[action_index]  # Extract the action verb
        obj = " ".join(words[action_index + 1:])  # Extract the object

        affirmative = f"{subject} {action} {obj}."  # Form the affirmative sentence

        # return affirmative.capitalize() + '.'  # Capitalize the first letter and add a period
        return affirmative + '.'

    return None

# Example usage
# question = "Who is going to the party?"
# question = "Who is the president of the USA?"
# question = "Who painted Mona Lisa?"
# question = "Who won Nobel Prize in Physics in 2022?"
Text="""
Who is the president of the USA?#	∃x (person(x) ∧ president(x) ∧ country(x, "USA"))
Who was the author of "Alice's Adventures in Wonderland"?#	∃x (person(x) ∧ author(x, "Alice's Adventures in Wonderland"))
Who attended the conference last week?#	∃x (person(x) ∧ attend(x, conference) ∧ time(x, last_week))
Who painted the Mona Lisa?#	∃x (person(x) ∧ paint(x, "Mona Lisa"))
Who is the CEO of Apple Inc.?#	∃x (person(x) ∧ CEO(x, "Apple Inc."))
Who discovered the theory of relativity?#	∃x (person(x) ∧ discover(x, "theory of relativity"))
Who won the Nobel Prize in Physics in 2020?#	∃x (person(x) ∧ win(x, "Nobel Prize in Physics", 2020))
Who wrote the play "Romeo and Juliet"?#	∃x (person(x) ∧ write(x, "Romeo and Juliet"))
Who founded Microsoft?#	∃x (person(x) ∧ founder(x, "Microsoft"))
Who composed the Symphony No. 9?#	∃x (person(x) ∧ compose(x, "Symphony No. 9"))
"""
# sentences = Text.split('\n')
# sentences = [sentence.strip() for sentence in sentences if sentence.strip() != ""]
#
# for row in sentences:
#   words=row.split("#")
#   question=words[0]
#   predicate=words[1]
#   print()
#   print(question)
#   affirmative_sentence = who_question_to_affirmative(question)
#   print(affirmative_sentence)
#   print(predicate)

# ChatGPT: Write a Python Code to change a When Question to affirmative sentence
def when_question_to_affirmative(question):
    # question=question.lower()
    if question.find("When") > -1 or question.find("when") > -1:
        question = question[:-1]  # Remove the question mark

        words = question.split()  # Split the question into words
        # print(words)
        if question.find("When") > -1:
            action_index = words.index("When") + 1  # Find the index of the action verb
        elif question.find("when") > -1:
            action_index = words.index("when") + 1  # Find the index of the action verb

        if action_index >= len(words):
            return "Invalid 'When' question."

        subject = "X"
        action = words[action_index]  # Extract the action verb
        obj = " ".join(words[action_index + 1:])  # Extract the object

        affirmative = f"{subject} {action} {obj}."  # Form the affirmative sentence

        # return affirmative.capitalize() + '.'  # Capitalize the first letter and add a period
        return affirmative + '.'

    return None

# Example usage
# question = "Who is going to the party?"
# question = "Who is the president of the USA?"
# question = "Who painted Mona Lisa?"
# question = "Who won Nobel Prize in Physics in 2022?"
Text="""
When did World War II start?#	∃t (wwii(t) ∧ start_at(wwii, t))
When did the event take place?#	∃t (event(t) ∧ take_place(event, t))
When did Shakespeare write "Hamlet"?#	∃t (shakespeare(t) ∧ write(shakespeare, "Hamlet", t))
When was the Declaration of Independence signed?#	∃t (declaration_of_independence(t) ∧ signed_at(declaration_of_independence, t))
When did the moon landing occur?#	∃t (moon_landing(t) ∧ occur_at(moon_landing, t))
When was the company founded?#	∃t (company(t) ∧ founded_at(company, t))
When did the Renaissance period begin?#	∃t (renaissance_period(t) ∧ begin_at(renaissance_period, t))
When did the first computer program run?#	∃t (first_computer_program(t) ∧ run_at(first_computer_program, t))
When was the movie released?#	∃t (movie(t) ∧ released_at(movie, t))

"""
# sentences = Text.split('\n')
# sentences = [sentence.strip() for sentence in sentences if sentence.strip() != ""]
#
# for row in sentences:
#   words=row.split("#")
#   question=words[0]
#   predicate=words[1]
#   print()
#   print(question)
#   affirmative_sentence = when_question_to_affirmative(question)
#   print(affirmative_sentence)
#   print(predicate)

# ChatGPT: Write a Python Code to change a What Question to affirmative sentence
def what_question_to_affirmative(question):
    # question=question.lower()
    if question.find("What") > -1 or question.find("what") > -1:
        question = question[:-1]  # Remove the question mark

        words = question.split()  # Split the question into words
        if question.find("What") > -1:
            action_index = words.index("What") + 1  # Find the index of the action verb
        elif question.find("what") > -1:
            action_index = words.index("what") + 1  # Find the index of the action verb

        if action_index >= len(words):
            return "Invalid 'What' question."
        subject="X"
        action = words[action_index]  # Extract the action verb
        obj = " ".join(words[action_index + 1:])  # Extract the object

        affirmative = f"{subject} {action} {obj}."  # Form the affirmative sentence

        return affirmative

    return None

def which_question_to_affirmative(question):
    # question=question.lower()
    if question.find("Which") or question.find("which"):
        question = question[:-1]  # Remove the question mark

        words = question.split()  # Split the question into words
        if question.find("Which") > -1:
            action_index = words.index("Which") + 1  # Find the index of the action verb
        elif question.find("which") > -1:
            action_index = words.index("which") + 1  # Find the index of the action verb

        if action_index >= len(words):
            return "Invalid 'Which' question."
        subject="X"
        action = words[action_index]  # Extract the action verb
        obj = " ".join(words[action_index + 1:])  # Extract the object

        affirmative = f"{subject} {action} {obj}."  # Form the affirmative sentence

        return affirmative

    return None

def why_question_to_affirmative(question):
    # question=question.lower()
    if question.find("Why") or question.find("why"):
        question = question[:-1]  # Remove the question mark

        words = question.split()  # Split the question into words
        if question.find("Why") > -1:
            action_index = words.index("Why") + 1  # Find the index of the action verb
        elif question.find("why") > -1:
            action_index = words.index("why") + 1  # Find the index of the action verb

        if action_index >= len(words):
            return "Invalid 'Why' question."
        subject="X"
        action = words[action_index]  # Extract the action verb
        obj = " ".join(words[action_index + 1:])  # Extract the object

        affirmative = f"{subject} {action} {obj}."  # Form the affirmative sentence

        return affirmative

    return None
# Example usage
# question = "What is the capital of France?"
# question = "What is the population of France?"
# question = "What are the symptons of COVID-19?"
Text="""
What is the capital of France?#	∃x (capital_of(x, "France"))
What is the meaning of life?#	meaning_of("life", x)
What are the ingredients of a pizza?#	ingredients_of("pizza", x)
What caused the earthquake?#	cause_of("earthquake", x)
What is the population of China?#	population_of("China", x)
What are the primary colors?#	primary_colors(x)
What is the purpose of education?#	purpose_of("education", x)
What is the title of the book?#	title_of("book", x)
What are the symptoms of COVID-19?#	symptoms_of("COVID-19", x)
What is the result of the experiment?#	result_of("experiment", x)
"""
# sentences = Text.split('\n')
# sentences = [sentence.strip() for sentence in sentences if sentence.strip() != ""]
#
# for row in sentences:
#   words=row.split("#")
#   question=words[0]
#   predicate=words[1]
#   print()
#   print(question)
#   affirmative_sentence = what_question_to_affirmative(question)
#   print(affirmative_sentence)
#   print(predicate)

import re

import spacy

def detect_pos(sentence):
    # Load the English language model
    nlp = spacy.load("en_core_web_sm")

    # Process the input sentence
    doc = nlp(sentence)

    # Extract POS tags and words
    pos_tags = [(token.text, token.pos_) for token in doc]

    return pos_tags


def convert_question_to_affirmative(question):
    # question=question.lower()
    pos_tags = detect_pos(question)
    #  Print the POS tags
    pos_tag_str=""
    soverb=0
    for word, pos in pos_tags:
       pos_tag_str+=" "+pos
       if pos in ["AUX","VERB"]:
          soverb+=1
    # print(pos_tag_str,soverb)
    if question.find("Where") or question.find("where") :
        question = question[:-1]  # Remove the question mark
        action_index = 0
        words = question.split()  # Split the question into words
        if question.find('Where') > -1:
            action_index = words.index("Where") + 1  # Find the index of the action verb
        elif question.find('where') > -1:
            action_index = words.index("where") + 1  # Find the index of the action verb

        subject = "X"
        action = words[action_index]  # Extract the action verb
        obj = " ".join(words[action_index + 1:])  # Extract the object

        affirmative = f"{subject} {action} {obj}."  # Form the affirmative sentence

        return affirmative

    elif question.find("Who") > -1 or question.find("who") > -1:
      return who_question_to_affirmative(question)
    elif question.find("What") > -1 or question.find("what") > -1:
      return what_question_to_affirmative(question)
    elif question.find("When") > -1 or question.find("when") > -1:
      return when_question_to_affirmative(question)
    elif question.find("Which") > -1 or question.find("which") > -1:
      return which_question_to_affirmative(question)
    elif question.find("Why") > -1 or question.find("why") > -1:
      return why_question_to_affirmative(question)

    return None

import csv

# !pip install transformers wikipedia newspaper3k GoogleNews pyvis

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import math
import torch
# import wikipedia
# from pyvis.network import Network

# Load model and tokenizer
tokenizer = AutoTokenizer.from_pretrained("Babelscape/rebel-large")
model = AutoModelForSeq2SeqLM.from_pretrained("Babelscape/rebel-large")

def extract_relations_from_model_output(text):
    relations = []
    relation, subject, relation, object_ = '', '', '', ''
    text = text.strip()
    current = 'x'
    text_replaced = text.replace("<s>", "").replace("<pad>", "").replace("</s>", "")
    for token in text_replaced.split():
        if token == "<triplet>":
            current = 't'
            if relation != '':
                relations.append({
                    'head': subject.strip(),
                    'type': relation.strip(),
                    'tail': object_.strip()
                })
                relation = ''
            subject = ''
        elif token == "<subj>":
            current = 's'
            if relation != '':
                relations.append({
                    'head': subject.strip(),
                    'type': relation.strip(),
                    'tail': object_.strip()
                })
            object_ = ''
        elif token == "<obj>":
            current = 'o'
            relation = ''
        else:
            if current == 't':
                subject += ' ' + token
            elif current == 's':
                object_ += ' ' + token
            elif current == 'o':
                relation += ' ' + token
    if subject != '' and relation != '' and object_ != '':
        relations.append({
            'head': subject.strip(),
            'type': relation.strip(),
            'tail': object_.strip()
        })
    return relations

class KB():
    def __init__(self):
        self.relations = []

    def are_relations_equal(self, r1, r2):
        return all(r1[attr] == r2[attr] for attr in ["head", "type", "tail"])

    def exists_relation(self, r1):
        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)

    def add_relation(self, r):
        if not self.exists_relation(r):
            self.relations.append(r)

    def print(self):
        print("Relations:")
        for r in self.relations:
            print(f"  {r}")

def from_small_text_to_kb(text, verbose=False):
    kb = KB()

    # Tokenizer text
    model_inputs = tokenizer(text, max_length=512, padding=True, truncation=True,
                            return_tensors='pt')
    if verbose:
        print(f"Num tokens: {len(model_inputs['input_ids'][0])}")

    # Generate
    gen_kwargs = {
        "max_length": 216,
        "length_penalty": 0,
        "num_beams": 3,
        "num_return_sequences": 3
    }
    generated_tokens = model.generate(
        **model_inputs,
        **gen_kwargs,
    )
    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)

    # create kb
    for sentence_pred in decoded_preds:
        relations = extract_relations_from_model_output(sentence_pred)
        for r in relations:
            kb.add_relation(r)

    return kb

# def question_to_affirmative(question):
#     question_words = ['who', 'Who', 'when', 'When', 'where', 'Where', 'which', 'Which', 'what', 'What', 'why', 'Why']
#
#     question = question.replace('?','')
#     for i in question_words:
#         question = question.replace(i, 'X Y Z')
#     return question
# import spacy
# nlp = spacy.load('en_core_web_sm')
def question2affirmative(question):

    question_words = ['who', 'when', 'where', 'which', 'what']
    stop_words = ['nsubj', 'nsubj:pass', 'aux:pass', 'cop', 'aux']
    aux_words = ['aux:pass', 'cop', 'aux']
    ques_intent = []
    predicate = ''

    nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')

    # question ='The 1999 film "10 Things I Hate About You" is based on which Shakespeare play?'
    # question = 'Who began as a Broadway actor, made his Hollywood debut in 1935, and had lead roles in The Grapes of Wrath, The Ox-Bow Incident, Mister Roberts and 12 Angry Men?'
    # question = 'Jesse Owens, who won four gold medals at the 1936 Summer Olympics in Berlin, Germany, represented who country?'
    # question = 'What was the name of the horse that Bob Champion rode to victory in the 1981 Grand National'
    doc = nlp(question[:])

    print(*[f'id: {word.id}\tword: {word.text}\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\n')
    affirmative_sent = []
    # for token in doc:

    for sent in doc.sentences:
        ques_phrase = []
        question_word_id = 0
        for word in sent.words:
            if len(ques_phrase) == 0:
                if word.deprel in ['det'] and str(word.text).lower() in question_words:
                    print(f'word id:{word.id} - word text: {word.text}')
                    ques_phrase.append(word.text)
                    question_word_id = word.id
                    sent.words[word.id-1].text = 'X'
                elif word.deprel == 'advmod' and str(word.text).lower() in question_words:
                    print(f'word id:{word.id} - word text: {word.text}')
                    ques_phrase.append(word.text)
                    question_word_id = word.id
                    sent.words[word.id-1].text = 'X'
                elif word.deprel == 'root' and str(word.text).lower() in question_words:
                    print(f'word id:{word.id} - word text: {word.text}')
                    ques_phrase.append(word.text)
                    question_word_id = word.id
                    sent.words[word.id-1].text = 'X'
                elif word.deprel in ['nsubj', 'nsubj:pass'] and str(word.text).lower() in question_words and word.id == 1:
                    print(f'word id:{word.id} - word text: {word.text}')
                    ques_phrase.append(word.text)
                    question_word_id = word.id
                    sent.words[word.id-1].text = 'X'
                    break
            else:
                if word.deprel not in stop_words and word.deprel != 'root':
                    ques_phrase.append(word.text)
                    ques_intent.append(word.text)
                elif word.deprel not in aux_words and word.deprel != 'root':
                    ques_phrase.append(word.text)
                    ques_intent.append(word.text)
                    break

        for w in sent.words:
            affirmative_sent.append(w.text)


        break
    return ' '.join(affirmative_sent)

# print(question2affirmative('When did Lord Salisbury leave office as Prime Minister?'))

def check_negation_operator_in_sentence(question):
  negation_words = ['didnot', 'donot', 'doesnot', 'willnot', 'maynot', 'couldnot', 'cannot', 'not', "n't", 'no', 'nobody', 'nothing']
  for w in negation_words:
    if w in question:
      return True
  return False

def get_entities(relations):
    rel = set()
    for r in relations:
    # print(r['head'], r['tail'])
        rel.add(r['head'])
        rel.add(r['tail'])

    return list(rel)

def check_negative(question):
    negation_root_words = ['didnot', 'donot', 'doesnot', 'willnot', 'maynot', 'couldnot']
    negation_cop_words =['cannot']
    advmod_words=['not', "n't"]
    nsubj_words = ['noones', 'nobody', 'nothing']
    negation_words = ['didnot', 'donot', 'doesnot', 'willnot', 'maynot', 'couldnot', 'cannot', 'not', "n't", 'no', 'nobody', 'nothing']
    predicate = ''
    question = question.replace('?', '')
    nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')
    # question ='The 1999 film "10 Things I Hate About You" is based on which Shakespeare play?'
    # question = 'Who began as a Broadway actor, made his Hollywood debut in 1935, and had lead roles in The Grapes of Wrath, The Ox-Bow Incident, Mister Roberts and 12 Angry Men?'
    # question = 'Jesse Owens, who won four gold medals at the 1936 Summer Olympics in Berlin, Germany, represented who country?'
    # question = 'What was the name of the horse that Bob Champion did not ride to victory in the 1981 Grand National?'
    # question = "Who was not ousted as Panama 's leader after a 1989 US invasion ordered by President George H.W. Bush , was convicted of drug racketeering and related charges in 1992 , and was extradited to France at the end of April 2010 on charges of laundering around US $ 3 million in drug proceeds by buying luxury apartments in Paris ?"
    # question = 'X was not the name of the horse that Bob Champion rode to victory in the 1981 Grand National'
    doc = nlp(question[:])
    # print(*[f'id: {word.id}\tword: {word.text}\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\n')
    kb = from_small_text_to_kb(question)
    relations = kb.relations
    rel_set = []
    for sent in doc.sentences:
        ques_phrase = []

        for word in sent.words:
          if word.text in negation_words:
            negation_position = question.find(word.text)
            entity = get_entities(relations)

            ent_pos = []
            print(f'negation {negation_position}')
            for e in entity:
              ent_pos.append(question.find(e))
              print(f'{e}--{question.find(e)}')

            min_pos = min(ent_pos)

            ent_pos = sorted(ent_pos)
            print(ent_pos)
            s = 0
            new_sent = []
            if min_pos > 0:
              sub_question = question[0:min_pos + len(entity[ent_pos.index(min_pos)])]
              # if 'X Y Z' not in sub_question:
              #   new_sent.append(sub_question + ' X Y Z')
              #   new_sent.append('X Y Z ' + sub_question)
              # else:
              new_sent.append(sub_question)

            for i in range(len(ent_pos)-1):
              if ent_pos[i] == ent_pos[i+1]:
                continue
              sub_question = question[ent_pos[i]:ent_pos[i+1] + len(entity[i+1])]
              new_sent.append(sub_question)

            if (len(question) - ent_pos[-1]) > 0:
                new_sent.append(question[ent_pos[-1]:])
            print(new_sent)

            for t in new_sent:
                kb_triple = from_small_text_to_kb(t)
                relations = kb_triple.relations
                if check_negation_operator_in_sentence(t):
                    for r in relations:
                        if {'head':r['head'], 'type': '-' + r['type'], 'tail':r['tail']} not in rel_set:
                            if 'X' in r['head']:
                                r['head'] = 'X'
                            elif 'X' in r['tail']:
                                r['tail'] = 'X'
                            rel_set.append({'head':r['head'], 'type': '-' + r['type'], 'tail':r['tail']})
                else:
                    for r in relations:
                        if {'head':r['head'], 'type': r['type'], 'tail':r['tail']} not in rel_set:
                            if 'X' in r['head']:
                                r['head'] = 'X'
                            elif 'X' in r['tail']:
                                r['tail'] = 'X'
                            rel_set.append({'head':r['head'], 'type': r['type'], 'tail':r['tail']})

            break
        print(rel_set)
    return rel_set

def check_affirmative(question):
    question = question.replace('?','')
    kb = from_small_text_to_kb(question)
    relations = kb.relations
    rel_set = relations
    entity = get_entities(relations)
    ent_pos = []
    if 'X' not in entity:
        # rel_set = []
        for e in entity:
          ent_pos.append(question.find(e))
          print(f'{e}--{question.find(e)}')

        min_pos = min(ent_pos)

        ent_pos = sorted(ent_pos)
        # print(ent_pos)
        s = 0
        new_sent = []
        if min_pos > 0:
          sub_question = question[0:min_pos + len(entity[ent_pos.index(min_pos)])]
          # if 'X' not in sub_question:
          #   new_sent.append(sub_question + ' X')
          #   new_sent.append('X' + sub_question)
          # else:
          new_sent.append(sub_question)

        for i in range(len(ent_pos)-1):
            if ent_pos[i] == ent_pos[i+1]:
                continue
            sub_question = question[ent_pos[i]:ent_pos[i+1] + len(entity[i+1])]
            new_sent.append(sub_question)
        if (len(question) - ent_pos[-1]) > 0:
            new_sent.append(question[ent_pos[-1]:])
        print(new_sent)

        for t in new_sent:
            kb_triple = from_small_text_to_kb(t)
            relations = kb_triple.relations
            for r in relations:
                if {'head':r['head'], 'type': r['type'], 'tail':r['tail']} not in rel_set:
                    rel_set.append({'head':r['head'], 'type': r['type'], 'tail':r['tail']})


            break
        for i in range(len(rel_set)):
            if 'X' in rel_set[i]['head']:
                rel_set[i]['head'] = 'X'
            elif 'X' in rel_set[i]['tail']:
                rel_set[i]['tail'] = 'X'
        # print(rel_set)
    return rel_set


Text = """
Where is the Eiffel Tower located?#	∃x (place(x) ∧ location(eiffel_tower, x))
Where was Shakespeare born?#	∃x (place(x) ∧ born_in(shakespeare, x))
Where is the headquarters of Google?#	∃x (place(x) ∧ headquarters(google, x))
Where does the river Nile start?#	∃x (place(x) ∧ river_starts(river_nile, x))
Where did the battle of Gettysburg occur?#	∃x (place(x) ∧ battle_occurs(battle_gettysburg, x))
Where is the Grand Canyon located?#	∃x (place(x) ∧ location(grand_canyon, x))
"""
import json
import load_seq2seq
from load_seq2seq import Seq2Seq
# path = 'data/FreebaseQA-partial.json'
# path = 'data/FreebaseQA-train.json'
# path = 'data/FreebaseQA-eval.json'
# path = 'data/FreebaseQA-dev.json'
# path = 'data/WebQSP/WebQSP.train.json'
path = 'data/complexWebQustion/complex_web_questions/ComplexWebQuestions_train.json'

with open(path, 'r', encoding='utf-8') as f:
    data = json.load(f)

# sentences = []
# f = open('data/questions.txt','r')
# sentences = f.readlines()
# f.close()
# for i in data['Questions']:
#     sentences.append(i['RawQuestion'])
#     f.write(f"{i['RawQuestion']}\n")
    # print([i]['RawQuestion'])
# f.close()
# sentences = Text.split('\n')
# sentences = [sentence.strip() for sentence in sentences if sentence.strip() != ""]

seq = Seq2Seq()
seq.makeVocabulary()
encoder_input_data, _, _ = seq.makeHotEncoding()
# s = seq.str2HotCoding('Vườn Vua tọa lạc ở đâu?')
# print(s)
# input = s[0:1]
seq.loadSeq2SeqModel()
# out = seq.decode_sequence(input)
# print(out)

fb13_path = 'data/FB13/entities.txt'
rebel_rel_path = 'fb_relations.tsv'

yago13_path = 'data/YAGO13/entities.txt'
rebel_yago_rel_path = 'data/relations_count.tsv'
entites = []
relations = []

with open(fb13_path, 'r', encoding='utf-8') as f:
# with open(yago13_path, 'r', encoding='utf-8') as f:
    lines = f.readlines()
    for i in lines:
        entites.append(i.strip('\n').split('\t')[1].lower())  #FB
        # entites.append(i.strip('\n').lower())  # YAGO

with open(rebel_rel_path, 'r') as f:
# with open(rebel_yago_rel_path, 'r') as f:
    d = csv.reader(f, delimiter='\t')
    for i in d:
        relations.append(i[0])

f = open('data/CWQ_question_rules.csv', 'a', encoding='utf-8', newline='')
w = csv.writer(f, delimiter='\t')
# for i in data['Questions']: #FB13, YAGO13, WebQSP
for i in data:   #CWQ
    # answer_entity = i['Parses'][0]['Answers'][0]['AnswersName'][0].replace(' ', '_')  #FB13, YAGO13
    try:
        # answer_entity = i['Parses'][0]['Answers'][0]['EntityName'].replace(' ', '_')    #WebQSP
        answer_entity = i['answers'][0]['answer'].replace(' ', '_')  # CWQ
        # print(answer_entity)
        # if answer_entity in entites:  # FB, YAGO
        if str.lower(answer_entity) in entites: #WebQSP
            # answer_fb_entity.append([i['RawQuestion'], answer_entity])
            # question = i['RawQuestion'] #WebQSP, FB13, YAGO13
            question = i['webqsp_question']     #CWQ
            affirmative = question2affirmative(question)
            # if affirmative:
            print(affirmative)
            rs = check_negative(affirmative)
            reasoning_path = []
            triple_reasoning_path = []
            if len(rs) == 0:
                kb = check_affirmative(affirmative)
                print(kb)

                for r in kb:
                    if r['head'] != r['tail']:
                        if r['type'] in relations:
                            print(r['type'])
                            try:
                                s = seq.str2HotCoding(r['type'])
                                out = seq.decode_sequence(s[0:1]).strip('\n')
                                if f"{out.replace(' ', '_')}({r['head']},{r['tail']})" not in reasoning_path:
                                    reasoning_path.append(f"{out.replace(' ', '_')}({r['head']},{r['tail']})")
                                    triple_reasoning_path.append(f"{r['head']}\t{out.replace(' ','_')}\t{r['tail']}")
                            except:
                                continue

            else:
                print(rs)
                for r in rs:
                    try:
                        if r['head'] != r['tail']:
                            if r['type'] in relations and '-' in r['type']:
                                s = seq.str2HotCoding(r['type'][1:])
                                out = seq.decode_sequence(s[0:1]).strip('\n')
                                out = '-' + out
                                if f"{out.replace(' ', '_')}({r['head']},{r['tail']})" not in reasoning_path:
                                    reasoning_path.append(f"{out.replace(' ', '_')}({r['head']},{r['tail']})")
                                    triple_reasoning_path.append(f"{r['head']}\t{out.replace(' ', '_')}\t{r['tail']}")
                            else:
                                if '-' not in r['type']:
                                    s = seq.str2HotCoding(r['type'])
                                    out = seq.decode_sequence(s[0:1]).strip('\n')
                                else:

                                    s = seq.str2HotCoding(r['type'][1:])
                                    out = seq.decode_sequence(s[0:1]).strip('\n')
                                    out = '-' + out

                                if f"{out.replace(' ', '_')}({r['head']},{r['tail']})" not in reasoning_path:
                                    reasoning_path.append(f"{out.replace(' ', '_')}({r['head']},{r['tail']})")
                                    triple_reasoning_path.append(f"{r['head']}\t{out.replace(' ', '_')}\t{r['tail']}")
                    except:
                        continue
            if len(reasoning_path) > 0 and len(triple_reasoning_path) > 0:
                fol_rule = ' ^ '.join(reasoning_path)
                triple_fol_rule = '^'.join(triple_reasoning_path)
                print(fol_rule)
                w.writerow([question, answer_entity, fol_rule, triple_fol_rule])
    except:
        continue
f.close()


"""
for row in sentences[:20]:
#     # words=str(row).split("#")
#     # words=str(row)
    question=row
#     print()
#     print(question)
#
#

    affirmative = question2affirmative(question)
    # if affirmative:
    print(affirmative)
    rs = check_negative(affirmative)
    reasoning_path = []
    if len(rs) == 0:
        kb = check_affirmative(affirmative)
        print(kb)

        for r in kb:
            if r['head'] != r['tail']:
                s = seq.str2HotCoding(r['type'])
                out = seq.decode_sequence(s[0:1]).strip('\n')
                if f"{out.replace(' ','_')}({r['head']},{r['tail']})" not in reasoning_path:
                    reasoning_path.append(f"{out.replace(' ','_')}({r['head']},{r['tail']})")

    else:
        print(rs)
        for r in rs:
            if r['head'] != r['tail'] and f"{r['type'].replace(' ','_')}({r['head']},{r['tail']})" not in reasoning_path:
                s = seq.str2HotCoding(r['type'])
                out = seq.decode_sequence(s[0:1]).strip('\n')
                reasoning_path.append(f"{out.replace(' ','_')}({r['head']},{r['tail']})")
    fol_rule = ' ^ '.join(reasoning_path)
    print(fol_rule)
    w.writerow([question, fol_rule])

    # else:
    #     print("Could not convert:", question)
"""
